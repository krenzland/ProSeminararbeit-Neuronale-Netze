\section{Vom linearen Modell zum Neuronalen Netz}

\subsection{Das Perceptron als additatives lineares Modell}
Eines der klassischsten Modelle der Regressionsanalyse sind lineare Regression und die logistic Regression. \\

Es sind mathematisch simple Verfahren, die sogar analytisch lösbar sind - aber eben nicht immer ideale Ergebnisse erzielen: es gibt Probleme, die mit den Verfahren nicht lösbar sind. 
\\

Eine Weiterentwicklung ist das so genannte Perceptron.
Eine gängige Definitition ist die, die auch in \cite{bishop1995neural} verwendet wird: 
Ein Perceptron besteht aus einem Eingabe-Vektor $x$, einem Gewichtsvektor $w$ und einem Bias-Wert $b$. Es ist ein binärer Klassifizierer, der das Ergebniss mit Hilfe der folgenden Formel berechnet:

\begin{equation}
    y = \begin{cases}
               1               & w x + b > 0\\
               0               & \text{ansonsten}
           \end{cases}.
\end{equation}

In dieser Formel entspricht $wx$ dem Skalarprodukt.

\subsection{Das Perceptron als einfaches ANN}

Wie wir später sehen werden, kann das Perceptron auch als eine einfache Variante eines Feed-Forward-Neuronalen-Netzes mit nur einem Ausgangsneuronen, mit der Heaviside-Funktion

\begin{equation}
    \sigma = \begin{cases}
               1               & n \geq 0\\
               0               & n \leq 0
           \end{cases}
\end{equation}

als Aktivierungsfunktion interpretiert werden.\\

Auf den benutzen Trainingsalgorithmus werden wir nicht eingehen; der später betrachtete Backpropagation-Algorithmus für allgemeine ANNs ist auf Perceptrons übertragbar.

\subsection{Das XOR-Problem: nicht linear separierbare Probleme}
Es gibt viele Probleme, die von einem Perceptron nicht gelöst werden können. Es können nur Funktionen von linearen Modellen approximiert werden, die linear seperierbar sind. Da das Perceptron als Verknüfung von linearen Funktionen auch linear ist, kann auch es diese Klasse von Funktionen nicht lösen

\subsection{Die Lösung: Neuronale Netze}
Neuronale Netze sind eine Weiterentwicklung von Perceptrons. Sie besitzen noch eine (oder mehrere) weitere Schicht(en) Neuronen, die jedoch nicht nur lineare Transformationen durchführen, sondern zusätzlich noch eine nicht lineare. \\

Diese nicht-linearität ermöglicht es, auch nicht linear seperierbare Probleme zu lösen.\\

Durch die Nicht-linearität und durch die komplexere Verknüpfung resultiert ein nicht lineares Optimierungsproblem, das meistens nicht mehr analytisch zu lösen ist: es werden numerische Verfahren benutzt.


