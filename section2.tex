\section{Neuronale Netze} %TODO: Absplitten

\subsection{Die Aktivierungsfunktion}
Die Funktion, die pro Knoten die nicht-lineare Transformation durchführt, heißt Aktivierungsfunktion. \\
Häufig wird eine Funktion mit sigmoiden Erscheinungsbild gewählt, das heißt eine Funktion, die die Ergebnisse in ein bestimmtes Interval "zusammenquetscht" (Quelle) und ein an ein "S" erinnerndes Erscheinungsbild hat. 
\\
Die einfachste Funktion diesen Typs ist die so genannte logistische Funktion

\begin{equation}
\sigma_1(x) = \frac{1}{1+e^{-x}}
\end{equation}

oder der hyperbolische Tangens

\begin{equation}
\sigma_2(x) = \tanh(x) = \frac{1-e^{-2x}}{1+e^{-2x}} = \\
2 * \sigma_1(2x) -1
\end{equation}.

Der Hyperbolische Tangens hat in der Praxis eine bessere Laufzeit (vlg. LeCunn: Efficient Backprop)

Alternativ ReLu:
\begin{equation}
\sigma_3(x) = \max(0,x)
\end{equation} bis zu 6 mal schneller (TODO: Quelle) \\
%Evtl.  Xavier Glorot, Antoine Bordes and Yoshua Bengio (2011). Deep sparse rectifier neural networks?
...

\subsection{Die Kostenfunktion}
Wir benutzen eine Kostenfunktion, die den durchschnittlichen Fehler des ANN-Ergebnis quantifiziert.\\

Bei Regression wird meistens die Summe der quadrierten Terme benutzt(entspricht der euklidischen Norm): 
\begin{equation}
J(\theta) = \sum_{k=1}^K \sum_{i=1}^N \left( \hat{Y_i} - Y_i \right)^2
\end{equation}

$\hat{Y_I}$ entspricht dem Ergniss des ANN, $Y$ dem richtigen Ergebniss. \\

Bei Klasssifizierungsproblemen wird üblicherweise die euklidische Norm, oder aber die negative Cross entropy benutzt \cite{Hastie2009}:

\begin{equation}
    J(\theta) = -\sum_{k=1}^K \sum_{i=1}^N y_{i_k} *
    \log f_k(x_i)
\end{equation}

Bei Klassifikationsproblem ist Cross entropy fast immer die bessere Wahl. \todo{Warum ist Cross entropy besser?}



\subsection{Die Minimierung der Kostenfunktion - Backpropagation}

Die gewählte Kostenfunktion gilt es nun zu minimieren. \\

Backpropagation ist der bei Neuronalen Netzen benutze Trainingsalgorithmus. \\

Er wird benutzt, um den Gradient der Kostenfunktion in Bezug auf alle Gewichte zu berechnen. \\

Dieser wird dann mit Hilfe einer geeigneten numerischen Methode benutzt, um die Gewichte zu optimieren. \\

Am Ende wird das Ergebniss der Optimierungsmethode benutzt, um die Gewichte zu aktualisieren.

\todo{Backpropagation}

\subsection{Die numerische Methode - Gradient Descent und verwandte}

Der Gradient wird oft mit der bekannten numerischen Methode Gradient Descent(eingedeutscht: Verfahren des steilen Abstiegs) benutzt.

Er ist relativ simpel:

\todo{Gradient Descent (primär Formel)}

Man unterscheidet beim Training von ANNs zwischen Batch und Stochastic Gradient Descent.\\

Bei der Batch Methode werden alle Gewichte auf einmal aktualisiert, bei Stochastic GD nur einzelne, zufällig ausgewählte Gewichte.\\

Das Gradientenverfahren hat das Problem, dass es oft in lokalen Minima steckenbleibt - das ist vor allem bei ANNs problematisch, weil die gewählte Kostenfunktion in den meisten Fällen mehrere lokale Minima besitzt. Auch wenn es nicht unbedingt notwendig, oder sogar erwünscht ist, einen globalen Extremwert zu finden (vgl. Overfitting), existieren bessere numerische Verfahren. \\

Eine Verbesserung zum gewöhnlichen Gradientenverfahren ist es, einen so genannten Momentumparameter zu benutzen, der auch vorherige Ergebnisse einbezieht, und somit das oft beobachtete oszillierende Verhalten des Gradientenverfahrens behebt.

\begin{equation}
 \mathbf{b} = \mathbf{a}-\gamma\nabla F(\mathbf{a}) + \text{Momentum}
\end{equation}