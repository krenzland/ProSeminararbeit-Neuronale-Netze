% This file was created with JabRef 2.10b2.
% Encoding: UTF-8


@InCollection{bengio2012practical,
  Title                    = {Practical recommendations for gradient-based training of deep architectures},
  Author                   = {Bengio, Yoshua},
  Booktitle                = {Neural Networks: Tricks of the Trade},
  Publisher                = {Springer},
  Year                     = {2012},
  Pages                    = {437--478}
}

@Book{bishop1995neural,
  Title                    = {Neural networks for pattern recognition},
  Author                   = {Bishop, Christopher M},
  Publisher                = {Clarendon press Oxford},
  Year                     = {1995}
}

@Article{cybenko1989approximation,
  Title                    = {Approximation by superpositions of a sigmoidal function},
  Author                   = {Cybenko, George},
  Journal                  = {Mathematics of control, signals and systems},
  Year                     = {1989},
  Number                   = {4},
  Pages                    = {303--314},
  Volume                   = {2},

  Publisher                = {Springer}
}

@Book{duda2012pattern,
  Title                    = {Pattern classification},
  Author                   = {Duda, Richard O and Hart, Peter E and Stork, David G},
  Publisher                = {John Wiley \& Sons},
  Year                     = {2012},

  Comment                  = {Chapters 6.1 -- 6.5 pp 282 -- 303},
  Owner                    = {lukaskrenz}
}

@InProceedings{glorot2010understanding,
  Title                    = {Understanding the difficulty of training deep feedforward neural networks},
  Author                   = {Glorot, Xavier and Bengio, Yoshua},
  Booktitle                = {International conference on artificial intelligence and statistics},
  Year                     = {2010},
  Pages                    = {249--256}
}

@InProceedings{glorot2011deep,
  Title                    = {Deep sparse rectifier networks},
  Author                   = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
  Booktitle                = {Proceedings of the 14th International Conference on Artificial Intelligence and Statistics. JMLR W\&CP Volume},
  Year                     = {2011},
  Pages                    = {315--323},
  Volume                   = {15}
}

@Book{Hastie2009,
  Title                    = {The elements of statistical learning},
  Author                   = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome and Hastie, T and Friedman, J and Tibshirani, R},
  Publisher                = {Springer},
  Year                     = {2009},
  Number                   = {1},
  Volume                   = {2}
}

@InCollection{lecunefficient,
  Title                    = {Efficient backprop},
  Author                   = {LeCun, Yann A and Bottou, L{\'e}on and Orr, Genevieve B and M{\"u}ller, Klaus-Robert},
  Booktitle                = {Neural networks: Tricks of the trade},
  Publisher                = {Springer},
  Year                     = {2012},
  Pages                    = {9--48}
}

@Article{LeCun2015,
  Title                    = {Deep learning},
  Author                   = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  Journal                  = {Nature},
  Year                     = {2015},

  Month                    = {May},
  Note                     = {Insight},
  Number                   = {7553},
  Pages                    = {436-444},
  Volume                   = {521},

  Abstract                 = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
  Day                      = {28},
  ISSN                     = {0028-0836},
  Publisher                = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  Url                      = {http://dx.doi.org/10.1038/nature14539}
}

@InProceedings{ngiam2011optimization,
  Title                    = {On optimization methods for deep learning},
  Author                   = {Ngiam, Jiquan and Coates, Adam and Lahiri, Ahbik and Prochnow, Bobby and Le, Quoc V and Ng, Andrew Y},
  Booktitle                = {Proceedings of the 28th International Conference on Machine Learning (ICML-11)},
  Year                     = {2011},
  Pages                    = {265--272}
}

@Article{rumelhart1988learning,
  Title                    = {Learning representations by back-propagating errors},
  Author                   = {Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  Journal                  = {Cognitive modeling},
  Year                     = {1988},
  Volume                   = {5}
}

